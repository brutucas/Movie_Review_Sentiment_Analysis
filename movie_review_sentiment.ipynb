{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "imdb_review_df = pd.read_csv('Data/IMDB Dataset.csv')\n",
    "imdb_review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of positive and negative reviews\n",
    "print('Number of positive and negative reviews: ', imdb_review_df['sentiment'].value_counts())\n",
    "# Find the proportion of positive and negative reviews\n",
    "print('Proportion of positive and negative reviews: ', imdb_review_df['sentiment'].value_counts() / len(imdb_review_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_reviews = imdb_review_df['review'].str.len()\n",
    "\n",
    "# How long is the longest review?\n",
    "print(f\"There are {len(length_reviews)} reviews in the dataframe.\")\n",
    "print(f\"The longest review is {max(length_reviews)} characters long.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(review):\n",
    "    sentiment = TextBlob(review).sentiment\n",
    "    return sentiment\n",
    "\n",
    "imdb_review_polarity = imdb_review_df['review'].apply(get_sentiment)\n",
    "imdb_review_polarity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sentiment of first review: {imdb_review_polarity[0]}\")\n",
    "print(f\"Sentiment of second review: {imdb_review_polarity[1]}\")\n",
    "print(f\"Sentiment of last review: {imdb_review_polarity.iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_review = max(imdb_review_df['review'], key=len)\n",
    "print(longest_review)\n",
    "print('\\n')\n",
    "longest_review_blob = TextBlob(longest_review)\n",
    "print(f\"Sentiment of the longest film review: {longest_review_blob.sentiment}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "longest_review_wc = WordCloud(\n",
    "    background_color='white', \n",
    "    stopwords=set(stopwords.words('english'))\n",
    "    ).generate(longest_review)\n",
    "\n",
    "plt.imshow(longest_review_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit([imdb_review_df['review'][0]])\n",
    "first_review_bow = vectorizer.transform([imdb_review_df['review'][0]])\n",
    "print(first_review_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_vect = CountVectorizer(\n",
    "    max_features=1000, \n",
    "    ngram_range=(1,2), \n",
    "    max_df=500, min_df=25, \n",
    "    stop_words='english',\n",
    "    token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b'\n",
    "    )\n",
    "\n",
    "reviews_vect.fit(imdb_review_df['review'])\n",
    "\n",
    "X_reviews = reviews_vect.transform(imdb_review_df['review'])\n",
    "X_count_df = pd.DataFrame(X_reviews.toarray(), columns=reviews_vect.get_feature_names_out())\n",
    "print(X_count_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of vectorizer: ', reviews_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "print(word_tokenize(imdb_review_df['review'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokens = [word_tokenize(review) for review in imdb_review_df['review']]\n",
    "print(reviews_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokens = [[word for word in review if word.isalpha()] for review in reviews_tokens]\n",
    "print(cleaned_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "reviews_wc = WordCloud(background_color='white', stopwords=english_stopwords).generate(all_reviews_text)\n",
    "plt.imshow(reviews_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\"\"\"\n",
    "\n",
    "\"\"\"# Create a concatenated string of all reviews\n",
    "all_reviews_text = ' '.join(imdb_review_df['review'])\n",
    "\n",
    "# Tokenize the concatenated text\n",
    "tokenized_reviews = word_tokenize(all_reviews_text)\n",
    "\n",
    "# Print the tokenized reviews\n",
    "print(tokenized_reviews)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "WNLemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lem_tokens = [WNLemmatizer.lemmatize(token) for sublist in cleaned_tokens for token in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_model = TfidfVectorizer(\n",
    "    max_features=1000, \n",
    "    ngram_range=(1,2), \n",
    "    max_df=500, min_df=25, \n",
    "    stop_words='english',\n",
    "    token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b'\n",
    ")\n",
    "\n",
    "reviews_tfidf = tfidf_model.fit_transform(imdb_review_df['review'])\n",
    "\n",
    "X_tfidf = pd.DataFrame(reviews_tfidf.toarray(), columns=tfidf_model.get_feature_names_out())\n",
    "print(X_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top 5 rows using BOW: \\n', X_count_df.head(5))\n",
    "print('Top 5 rows using TF-IDF: \\n', X_tfidf.head(5))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
